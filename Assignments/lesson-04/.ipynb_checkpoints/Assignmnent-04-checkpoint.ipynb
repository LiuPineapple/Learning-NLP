{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([11231, 999, 123142])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = np.array([-10, 10, 24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(vec):\n",
    "    vec -= np.max(vec)\n",
    "    exp = np.exp(vec)\n",
    "    return exp / np.sum(exp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.71390701e-15, 8.31528028e-07, 9.99999168e-01])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment-04 基于维基百科的词向量构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在本章，你将使用Gensim和维基百科获得你的第一批词向量，并且感受词向量的基本过程。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 参考以下同学代码：\n",
    "https://github.com/vincent507cpu/nlp/blob/master/assignment/04/04.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://www.kaggleusercontent.com/kf/1018109/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..JNNggcCCDcYEypvp7ZDwOA.cM9CuDpuCKo0K_ZkMFLAUvhfip0P6SRZ4LddwgTtgwz8pQy1dZeGVJWi6u81KSpAFNSi7YximVVJbPw8xsFySdWlqoUwvSER-LLIRfmlpsCvtDt90NaLYT2FHlwl0tfF-1MKtiFsWlGQ8LGo40hL3ccBSwMZy214kGJf9bNkW_g.kZbF5sgN5qha3zhjilfSDg/__results___files/__results___9_0.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-01: Download Wikipedia Chinese Corpus: https://dumps.wikimedia.org/zhwiki/20190720/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一步：使用维基百科下载中文语料库"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-02: Using https://github.com/attardi/wikiextractor to extract the wikipedia corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二步：使用python wikipedia extractor抽取维基百科的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hanziconv import HanziConv\n",
    "import re\n",
    "import jieba\n",
    "from gensim.models.word2vec import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "#WikiExtractor.py C:\\Users\\13081\\Desktop\\Learning_Data\\wiki_Chinese_20190720\\wikiyasuo\\zhwiki-20190720-pages-articles-multistream.xml -o output\n",
    "#抽取维基百科内容这一步使用Pycharm完成\n",
    "#下面进行数据预处理：\n",
    "ptn1 = '<.+?>' \n",
    "ptn2 = \"[“”，。「」（）《》、\\'·\\\"\\-]\"\n",
    "\n",
    "outfile = open(r'D:\\Git_repositories\\Learning-NLP\\Assignments\\lesson-04\\file_processed.txt', 'w',encoding = 'utf-8')\n",
    "with open(r'D:\\Git_repositories\\wikiextractor\\text\\AA\\wiki_00',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        line = re.sub(ptn1, '', line)\n",
    "        line = re.sub(ptn2, '', line)\n",
    "        line = HanziConv.toSimplified(line)\n",
    "        outfile.write(line)\n",
    "    print(\"Done!\")\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\n', '数学\\n', '\\n', '数学是利用符号语言研究数量结构变化以及空间等概念的一门学科从某种角度看属于形式科学的一种数学透过抽象化和逻辑推理的使用由计数计算量度和对物体形状及运动的观察而产生数学家们拓展这些概念为了公式化新的猜想以及从选定的公理及定义中建立起严谨推导出的定理\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(r'D:\\Git_repositories\\Learning-NLP\\Assignments\\lesson-04\\file_processed.txt',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines(5)\n",
    "    print(lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\13081\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.547 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['\\n'], ['数学', '\\n'], ['\\n'], ['数学', '是', '利用', '符号语言', '研究', '数量', '结构', '变化', '以及', '空间', '等', '概念', '的', '一门', '学科', '从', '某种', '角度看', '属于', '形式', '科学', '的', '一种', '数学', '透过', '抽象化', '和', '逻辑推理', '的', '使用', '由', '计数', '计算', '量度', '和', '对', '物体', '形状', '及', '运动', '的', '观察', '而', '产生', '数学家', '们', '拓展', '这些', '概念', '为了', '公式化', '新', '的', '猜想', '以及', '从', '选定', '的', '公理', '及', '定义', '中', '建立', '起', '严谨', '推导', '出', '的', '定理', '\\n'], ['\\n']]\n",
      "[[], ['数学'], [], ['数学', '是', '利用', '符号语言', '研究', '数量', '结构', '变化', '以及', '空间', '等', '概念', '的', '一门', '学科', '从', '某种', '角度看', '属于', '形式', '科学', '的', '一种', '数学', '透过', '抽象化', '和', '逻辑推理', '的', '使用', '由', '计数', '计算', '量度', '和', '对', '物体', '形状', '及', '运动', '的', '观察', '而', '产生', '数学家', '们', '拓展', '这些', '概念', '为了', '公式化', '新', '的', '猜想', '以及', '从', '选定', '的', '公理', '及', '定义', '中', '建立', '起', '严谨', '推导', '出', '的', '定理'], []]\n",
      "[['数学'], ['数学', '是', '利用', '符号语言', '研究', '数量', '结构', '变化', '以及', '空间', '等', '概念', '的', '一门', '学科', '从', '某种', '角度看', '属于', '形式', '科学', '的', '一种', '数学', '透过', '抽象化', '和', '逻辑推理', '的', '使用', '由', '计数', '计算', '量度', '和', '对', '物体', '形状', '及', '运动', '的', '观察', '而', '产生', '数学家', '们', '拓展', '这些', '概念', '为了', '公式化', '新', '的', '猜想', '以及', '从', '选定', '的', '公理', '及', '定义', '中', '建立', '起', '严谨', '推导', '出', '的', '定理']]\n"
     ]
    }
   ],
   "source": [
    "token = []\n",
    "new_token = []\n",
    "newer_token = []\n",
    "with open(r'D:\\Git_repositories\\Learning-NLP\\Assignments\\lesson-04\\file_processed.txt',encoding = 'utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for i in range(1000000):\n",
    "        token.append(list(jieba.cut(lines[i]))) # database is too large, takes forever\n",
    "for snippet in token:\n",
    "    new_token.append([piece for piece in snippet if piece != \"\\n\"]) # replace \"\\n\" by whitespace\n",
    "newer_token = [piece for piece in new_token if piece] # remove whitespace\n",
    "print(token[:5])\n",
    "print(new_token[:5])\n",
    "print(newer_token[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step-03: Using gensim get word vectors:\n",
    "Reference:\n",
    "\n",
    "- https://radimrehurek.com/gensim/models/word2vec.html\n",
    "- https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第三步：参考Gensim的文档和Kaggle的参考文档，获得词向量。 注意，你要使用Jieba分词把维基百科的内容切分成一个一个单词，然后存进新的文件中。然后，你需要用Gensim的LineSentence这个类进行文件的读取。\n",
    "\n",
    "在训练成词向量Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Word2Vec(newer_token, size=100, window=20, min_count=5, workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.42463028, -1.6123226 , -2.710055  ,  4.244175  , -1.5378119 ,\n",
       "       -4.6059217 ,  3.0812287 ,  0.03009929, -4.152047  , -3.386837  ,\n",
       "       -4.5482903 ,  4.6051536 ,  0.20735261, -1.8265445 ,  0.12114535,\n",
       "        1.653623  ,  1.820315  , -2.3478963 ,  1.260447  , -5.594141  ,\n",
       "       -4.136625  ,  0.12940994, -1.9014697 ,  5.7157745 , -4.6608458 ,\n",
       "        4.6161356 , -0.17318381,  5.495559  ,  0.6074376 ,  1.8367327 ,\n",
       "       -1.5861133 ,  0.9399486 , -0.86059093, -5.0751696 , -1.4095215 ,\n",
       "       -0.4079171 ,  1.9257882 ,  2.7798648 , -0.30222183,  1.2072548 ,\n",
       "        1.4772428 ,  3.1051455 , -2.0823982 ,  0.7155619 , -5.289693  ,\n",
       "        0.9818822 ,  2.7984855 , -0.8556981 , -4.939082  ,  1.0505956 ,\n",
       "        6.0308294 ,  0.3739121 ,  0.54478014, -1.9412055 , -2.363672  ,\n",
       "       -3.3250225 ,  0.7841006 , -1.6962622 ,  1.9606502 , -8.944448  ,\n",
       "       -1.6607779 ,  2.4418776 ,  3.0827498 ,  4.0932016 , -0.7758474 ,\n",
       "        0.44879296, -1.8002441 ,  0.4463118 , -1.3176613 , -0.8903992 ,\n",
       "       -1.696004  ,  2.902562  , -5.8529506 ,  3.0016494 , -1.3373086 ,\n",
       "        1.4220511 , -0.5435031 ,  3.0648344 ,  2.4494169 , -1.8091981 ,\n",
       "       -0.97044396, -0.57819664, -1.5704126 , -2.7972126 , -3.3155346 ,\n",
       "        0.9733741 ,  3.861132  , -2.3107784 , -1.2685338 ,  1.3978719 ,\n",
       "        0.5555105 , -2.3894415 , -3.3133292 ,  2.395701  , -3.7139344 ,\n",
       "        2.261515  ,  3.9727    , -3.17775   ,  3.6277688 , -4.1361833 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv['数学']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5490341"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('数学', '科学')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-04: Using some words to test your preformance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第四步，测试同义词，找几个单词。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('可爱', 0.7465090155601501),\n",
       " ('美好', 0.6949734687805176),\n",
       " ('最美', 0.6904371976852417),\n",
       " ('丑陋', 0.6680330038070679),\n",
       " ('迷人', 0.6631984710693359),\n",
       " ('幸福', 0.6630998849868774),\n",
       " ('漂亮', 0.6584807634353638),\n",
       " ('优雅', 0.6491525173187256),\n",
       " ('寂寞', 0.6462000012397766),\n",
       " ('温柔', 0.6451581716537476)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(['美丽'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-05: Using visualization tools: https://www.kaggle.com/jeffd23/visualizing-word-vectors-with-t-sne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第五步：使用Kaggle给出的T-SEN进行词向量的可视化。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
