{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 我的作业"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基础理论部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0. Can you come up out 3 sceneraies which use AI methods?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {无人驾驶、语音识别、推荐系统}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. How do we use Github; Why do we use Jupyter and Pycharm;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans: {Github用于我们的代码托管，同时我们的作业也要放在Github上供批改；使用Jupyter的原因是它适合做交互调试和演示，使用Pycharm的原因是它适合做大型项目}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.What's the Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:概率模型是我们对于多个选项，利用模型计算其概率，选取概率最大的作为最优选项"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Can you came up with some sceneraies at which we could use Probability Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:人脸识别、无人驾驶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Why do we use probability and what's the difficult points for programming based on parsing and pattern match?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:我们使用概率是在很多问题中靠逻辑难以抉择，至于后面的问题我不太懂"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. What's the Language Model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:统计语言模型是一个单词序列上的概率分布，对于一个给定长度为m的序列，它可以为整个序列产生一个概率 P(w_1,w_2,…,w_m) 。其实就是想办法找到一个概率分布，它可以表示任意一个句子或序列出现的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Can you came up with some sceneraies at which we could use Language Model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:自动翻译、语音识别、对话机器人"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. What's the 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:就是只关心单个单词出现的频率，或者认为单个单词出现的频率与其旁边的单词无关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. What's the disadvantages and advantages of 1-gram language model;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:缺点是不够准确，与实际情况不符；优点是简单直观"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What't the 2-gram models;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:每个单词出现的概率至于和它相邻的单词有关而与其他单词无关"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 编程实践部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.设计你自己的句子生成器"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero = \"\"\"\n",
    "hero = 自我介绍 台词 询问\n",
    "自我介绍 = 寒暄 我是 名字 | 寒暄 我是 外号\n",
    "寒暄 = 你好， | 很高兴认识你， | 大唐欢迎你，\n",
    "名字 = 李白。 | 钟馗。 | 李元芳。\n",
    "外号 = 剑仙。 | 地府判官。 | 王都密探。\n",
    "台词 = 大河之剑天上来！ | 对付魑魅魍魉，乃是强迫症最佳疗法！ | 密探的小本本上羞答答，人生太复杂！\n",
    "询问 = 你是来跟我争天下第一的吗？ | 你是什么鬼？ | 你说的每一句话都将作为呈堂证供！\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第二个语法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_comments = \"\"\"\n",
    "movie_comments = 演员 动作 形容\n",
    "演员 = 大宝 | 书记 | 大宝 | 京哥\n",
    "动作 = 演的 | 表现 | 展现 | 演绎\n",
    "形容 = 好 | 不好 | 太棒了 | 太烂了 |很尴尬\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: 然后，使用自己之前定义的generate函数，使用此函数生成句子。\n",
    "\n",
    "TODO: 然后，定义一个函数，generate_n，将generate扩展，使其能够生成n个句子:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_grammer(grammer_str,split = '=>'):\n",
    "    grammer = {}\n",
    "    for line in grammer_str.split('\\n'):\n",
    "        if  not line.strip(): continue\n",
    "        exp,stmt = line.split(split)\n",
    "        grammer[exp.strip()] = [s.split() for s in stmt.split('|')]\n",
    "    return grammer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "hero1 = create_grammer(hero,split = '=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hero': [['自我介绍', '台词', '询问']],\n",
       " '自我介绍': [['寒暄', '我是', '名字'], ['寒暄', '我是', '外号']],\n",
       " '寒暄': [['你好，'], ['很高兴认识你，'], ['大唐欢迎你，']],\n",
       " '名字': [['李白。'], ['钟馗。'], ['李元芳。']],\n",
       " '外号': [['剑仙。'], ['地府判官。'], ['王都密探。']],\n",
       " '台词': [['大河之剑天上来！'], ['对付魑魅魍魉，乃是强迫症最佳疗法！'], ['密探的小本本上羞答答，人生太复杂！']],\n",
       " '询问': [['你是来跟我争天下第一的吗？'], ['你是什么鬼？'], ['你说的每一句话都将作为呈堂证供！']]}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hero1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(gram,target):\n",
    "    if target not in gram: return target\n",
    "    return ''.join(generate(gram,t) for t in random.choice(gram[target]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "choice = random.choice\n",
    "def generate01(gram, target):\n",
    "    if target not in gram: return target # means target is a terminal expression\n",
    "    \n",
    "    expaned = [generate(gram, t) for t in choice(gram[target])]\n",
    "    return ''.join([e if e != '/n' else '\\n' for e in expaned if e != 'null'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大唐欢迎你，我是王都密探。大河之剑天上来！你说的每一句话都将作为呈堂证供！'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate01(hero1,'hero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_n(n,gram,target):\n",
    "    for i in range(n):\n",
    "        print(generate01(gram,target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "大唐欢迎你，我是王都密探。密探的小本本上羞答答，人生太复杂！你是什么鬼？\n",
      "很高兴认识你，我是剑仙。密探的小本本上羞答答，人生太复杂！你是什么鬼？\n",
      "你好，我是李白。密探的小本本上羞答答，人生太复杂！你说的每一句话都将作为呈堂证供！\n",
      "你好，我是李白。对付魑魅魍魉，乃是强迫症最佳疗法！你是来跟我争天下第一的吗？\n",
      "很高兴认识你，我是李白。密探的小本本上羞答答，人生太复杂！你是来跟我争天下第一的吗？\n"
     ]
    }
   ],
   "source": [
    "generate_n(5,hero1,'hero')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "书记展现太棒了\n",
      "大宝展现很尴尬\n",
      "大宝表现太棒了\n",
      "京哥表现太烂了\n",
      "大宝展现好\n",
      "京哥演绎好\n"
     ]
    }
   ],
   "source": [
    "generate_n(6,create_grammer(movie_comments,split = '='),'movie_comments')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. 使用新数据源完成语言模型的训练"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "按照我们上文中定义的prob_2函数，我们更换一个文本数据源，获得新的Language Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本次作业使用的是数据集2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = r'C:\\Users\\Administrator\\Desktop\\movie_comments.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(filename,encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>link</th>\n",
       "      <th>name</th>\n",
       "      <th>comment</th>\n",
       "      <th>star</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京意淫到了脑残的地步，看了恶心想吐</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>https://movie.douban.com/subject/26363254/</td>\n",
       "      <td>战狼2</td>\n",
       "      <td>中二得很</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                        link name  \\\n",
       "0  1  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "1  2  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "2  3  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "3  4  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "4  5  https://movie.douban.com/subject/26363254/  战狼2   \n",
       "\n",
       "                                             comment star  \n",
       "0                                 吴京意淫到了脑残的地步，看了恶心想吐    1  \n",
       "1  首映礼看的。太恐怖了这个电影，不讲道理的，完全就是吴京在实现他这个小粉红的英雄梦。各种装备轮...    2  \n",
       "2  吴京的炒作水平不输冯小刚，但小刚至少不会用主旋律来炒作…吴京让人看了不舒服，为了主旋律而主旋...    2  \n",
       "3                      凭良心说，好看到不像《战狼1》的续集，完虐《湄公河行动》。    4  \n",
       "4                                               中二得很    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment = data['comment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31454"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(string):\n",
    "    # we will learn the regular expression next course.\n",
    "    return re.findall('\\w+', string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_clean = [''.join(token(str(a))) for a in comment]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'犯我中华者虽远必诛吴京比这句话还要意淫一百倍'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_clean[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_string(string): return list(jieba.cut(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_words = [cut_string(i) for i in comments_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a= 0\n",
    "for i in range(len(comment_words)):\n",
    "    a+= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "Token = []\n",
    "for i in range(len(comment_words)):\n",
    "    Token += comment_words[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京', '意淫', '到', '了', '脑残', '的', '地步', '看', '了', '恶心']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Token[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count = Counter(Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('的', 44015),\n",
       " ('了', 15596),\n",
       " ('是', 10603),\n",
       " ('我', 7664),\n",
       " ('都', 5600),\n",
       " ('看', 4850),\n",
       " ('也', 4724),\n",
       " ('电影', 4633),\n",
       " ('和', 4569),\n",
       " ('在', 4384),\n",
       " ('很', 4317),\n",
       " ('不', 4181),\n",
       " ('有', 4051),\n",
       " ('就', 3933),\n",
       " ('人', 3419),\n",
       " ('好', 3172),\n",
       " ('啊', 3030),\n",
       " ('你', 2833),\n",
       " ('还', 2655),\n",
       " ('这', 2528),\n",
       " ('还是', 2423),\n",
       " ('一个', 2417),\n",
       " ('但', 2199),\n",
       " ('没有', 2115),\n",
       " ('让', 2075),\n",
       " ('就是', 2063),\n",
       " ('剧情', 1991),\n",
       " ('故事', 1805),\n",
       " ('说', 1760),\n",
       " ('太', 1734),\n",
       " ('给', 1679),\n",
       " ('又', 1669),\n",
       " ('喜欢', 1664),\n",
       " ('没', 1654),\n",
       " ('吧', 1628),\n",
       " ('他', 1596),\n",
       " ('到', 1523),\n",
       " ('一部', 1502),\n",
       " ('上', 1501),\n",
       " ('被', 1494),\n",
       " ('能', 1490),\n",
       " ('得', 1488),\n",
       " ('对', 1434),\n",
       " ('这个', 1429),\n",
       " ('最后', 1421),\n",
       " ('多', 1369),\n",
       " ('什么', 1364),\n",
       " ('不错', 1357),\n",
       " ('最', 1353),\n",
       " ('真的', 1342),\n",
       " ('要', 1299),\n",
       " ('可以', 1279),\n",
       " ('好看', 1258),\n",
       " ('不是', 1257),\n",
       " ('觉得', 1229),\n",
       " ('自己', 1173),\n",
       " ('拍', 1153),\n",
       " ('感觉', 1130),\n",
       " ('去', 1121),\n",
       " ('想', 1112),\n",
       " ('这部', 1105),\n",
       " ('这么', 1105),\n",
       " ('片子', 1095),\n",
       " ('与', 1089),\n",
       " ('里', 1089),\n",
       " ('导演', 1079),\n",
       " ('把', 1078),\n",
       " ('但是', 1066),\n",
       " ('中', 1044),\n",
       " ('会', 1042),\n",
       " ('演技', 1031),\n",
       " ('那', 1015),\n",
       " ('着', 1003),\n",
       " ('大', 949),\n",
       " ('有点', 931),\n",
       " ('个', 930),\n",
       " ('挺', 927),\n",
       " ('更', 925),\n",
       " ('那么', 924),\n",
       " ('比', 922),\n",
       " ('不过', 903),\n",
       " ('再', 891),\n",
       " ('这种', 888),\n",
       " ('真是', 879),\n",
       " ('打', 862),\n",
       " ('这样', 857),\n",
       " ('虽然', 852),\n",
       " ('吗', 845),\n",
       " ('动作', 843),\n",
       " ('而', 833),\n",
       " ('小', 832),\n",
       " ('演员', 830),\n",
       " ('时候', 826),\n",
       " ('片', 817),\n",
       " ('来', 813),\n",
       " ('看到', 809),\n",
       " ('知道', 792),\n",
       " ('我们', 776),\n",
       " ('爱', 771),\n",
       " ('戏', 770)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_count.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_1(word):\n",
    "    return words_count[word] / len(Token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011950890464544664"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob1('我们')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = [str(t) for t in Token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_2_GRAM = [''.join(TOKEN[i:i+2]) for i in range(len(TOKEN[:-2]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['吴京意淫', '意淫到', '到了', '了脑残', '脑残的', '的地步', '地步看', '看了', '了恶心', '恶心想']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN_2_GRAM[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_count_2 = Counter(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_2(word1, word2):\n",
    "    if word1 + word2 in words_count_2: return words_count_2[word1+word2] / len(TOKEN_2_GRAM)\n",
    "    else:\n",
    "        return 1 / len(TOKEN_2_GRAM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6940747425776426e-05"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_2('我们', '在')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probability(sentence):\n",
    "    words = cut_string(sentence)\n",
    "    sentence_prob = 1\n",
    "    \n",
    "    for i, word in enumerate(words[:-1]):\n",
    "        next_word = words[i+1]\n",
    "        probability_1 = prob_1(next_word)\n",
    "        probability_2 = prob_2(word, next_word)\n",
    "        \n",
    "        sentence_prob *= (probability_2 / probability_1)\n",
    "    sentence_prob *= probability_1\n",
    "    return sentence_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.034305062967163e-14"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明今天的一台苹果手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.111991427873751e-15"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_probability('小明明天的一台苹果手机')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence: 大宝演绎不好 with Prb: 1.8555092667667764e-08\n",
      "sentence: 京哥表现太棒了 with Prb: 6.1602907656656984e-09\n",
      "sentence: 大宝展现好 with Prb: 1.9744521684825955e-08\n",
      "sentence: 书记演绎不好 with Prb: 1.8555092667667764e-08\n",
      "sentence: 大宝展现好 with Prb: 1.9744521684825955e-08\n",
      "sentence: 书记演的很尴尬 with Prb: 1.7647723674488738e-11\n",
      "sentence: 京哥表现太棒了 with Prb: 6.1602907656656984e-09\n",
      "sentence: 大宝展现不好 with Prb: 1.9744521684825955e-08\n",
      "sentence: 京哥演的不好 with Prb: 3.149075138645421e-10\n",
      "sentence: 京哥演绎太烂了 with Prb: 1.0773957959927268e-08\n"
     ]
    }
   ],
   "source": [
    "for sen in [generate(create_grammer(movie_comments,split = '='),'movie_comments') for i in range(10)]:\n",
    "    print('sentence: {} with Prb: {}'.format(sen, get_probability(sen)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.获得最优质的的语言"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "当我们能够生成随机的语言并且能判断之后，我们就可以生成更加合理的语言了。请定义 generate_best 函数，该函数输入一个语法 + 语言模型，能够生成n个句子，并能选择一个最合理的句子:\n",
    "\n",
    "提示，要实现这个函数，你需要Python的sorted函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_best(grammer,target,split,model,n): \n",
    "    sentences = [generate(create_grammer(grammer,split),target) for i in range(n)]\n",
    "    prob = [model(sentence) for sentence in sentences]\n",
    "    sens = list(enumerate(prob))\n",
    "    sens_sorted = sorted(sens,key=lambda x: x[1],reverse = True)\n",
    "    return sentences[sens_sorted[0][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'书记展现不好'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_best(movie_comments,'movie_comments','=',get_probability,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好了，现在我们实现了自己的第一个AI模型，这个模型能够生成比较接近于人类的语言。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q:这个模型有什么问题？ 你准备如何提升？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ans:问题：数据的数量还不太够，在计算条件概率时会出现prob1(word) = 0 的情况，同时数据来自影评，也会对句子合理性的判断造成影响。提升：增加数据量，或者说增加其他环境下的语料"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
